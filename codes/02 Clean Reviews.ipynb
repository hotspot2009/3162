{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Jupyter Notebook file which was born out of necessity because the review\n",
    "text lacks punctuations which is needed to get accurate aspects. The \n",
    "script does some manual restoration first, then pipes all the review text\n",
    "to a command which feeds the unpunctuated text to a punctuator model which\n",
    "outputs the text with correct punctuation with high accuracy. The punctuator\n",
    "uses a bidirectional recurrent neural network model with attention mechanism \n",
    "for restoring the missing punctuation in unsegmented text. The software is\n",
    "cited below.\n",
    "\n",
    "@inproceedings{tilk2016,\n",
    "  author    = {Ottokar Tilk and Tanel Alum{\\\"a}e},\n",
    "  title     = {Bidirectional Recurrent Neural Network with Attention Mechanism for Punctuation Restoration},\n",
    "  booktitle = {Interspeech 2016},\n",
    "  year      = {2016}\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import time\n",
    "\n",
    "# Assigning variable to library element which tokenizes on white space\n",
    "wt = nltk.tokenize.WhitespaceTokenizer()\n",
    "\n",
    "# Import processed sample data from '01 Fitting Dataset.ipynb'\n",
    "infile = open(\"Stored Data/sample_reviews.pickle\", \"rb\")\n",
    "data = pk.load(infile)\n",
    "infile.close()\n",
    "\n",
    "# Given unpunctuated text, restore missing punctuations \n",
    "# and return punctuated text\n",
    "def adjust_para(text):\n",
    "    text = str(text)\n",
    "    tokens = wt.tokenize(text)\n",
    "    \n",
    "    # the model doesn't work accurately on apostrophe so\n",
    "    # that is restored manually\n",
    "    for word in range(len(tokens)):\n",
    "        if tokens[word] == \"s\":\n",
    "            tokens[word] = \"'s\"\n",
    "        elif tokens[word] == \"t\":\n",
    "            tokens[word] = \"'t\"\n",
    "        elif tokens[word] == \"d\":\n",
    "            tokens[word] = \"'d\"\n",
    "        elif tokens[word] == \"ll\":\n",
    "            tokens[word] = \"'ll\"\n",
    "        elif tokens[word] == \"m\":\n",
    "            tokens[word] = \"'m\"\n",
    "        elif tokens[word] == \"o\":\n",
    "            tokens[word] = \"'o\"\n",
    "        elif tokens[word] == \"re\":\n",
    "            tokens[word] = \"'re\"\n",
    "        elif tokens[word] == \"ve\":\n",
    "            tokens[word] = \"'ve\"\n",
    "        elif tokens[word] == \"y\":\n",
    "            tokens[word] = \"'y\"\n",
    "    \n",
    "    # create a partial command\n",
    "    text = \" \".join(tokens).replace(\" '\", \"'\")\n",
    "    mod = \"text=\" + text\n",
    "    \n",
    "    # pipe the partial command to the punctuator model and get\n",
    "    # punctuated text\n",
    "    puntuator = !curl -d \"$mod\" http://bark.phon.ioc.ee/punctuator\n",
    "    \n",
    "    # return punctuated text\n",
    "    return puntuator[-1]\n",
    "\n",
    "# Create new column which for each row, stores punctuated review text\n",
    "data[\"Mod\"] = data['Reviews'].apply(lambda x: adjust_para(x))\n",
    "\n",
    "# Delete column containing unpunctuated review text, rename\n",
    "# the column containing punctuated review text to Reviews,\n",
    "# effectively replacing unpunctuated review column with\n",
    "# punctuated one\n",
    "data = data.drop(['Reviews'], axis=1)\n",
    "data = data.rename(index=str, columns={\"Mod\": \"Reviews\"})\n",
    "\n",
    "# Update the pickle file so that it now contains punctuated review text\n",
    "outfile = open(\"Stored Data/sample_reviews.pickle\", \"wb\")\n",
    "pk.dump(data, outfile)\n",
    "outfile.close()\n",
    "\n",
    "# Also write all of the reviews to a text file and formate it appropriately\n",
    "# as this file will then be passed to the Java code which extracts the aspects\n",
    "input_file = open(\"Stored Data/raw_review_input_file.txt\",\"w+\")\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    fixed_text = row['Reviews']\n",
    "    input_file.write(\"{}\\n\".format(fixed_text))\n",
    "    \n",
    "input_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
